{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Object-Aware Video Search System with BLIP & Grounding DINO\n",
        "\n",
        "This notebook implements a semantic video search engine that:\n",
        "- Extracts frames from videos with similarity-based filtering\n",
        "- Detects objects using Grounding DINO (optional)\n",
        "- Generates captions using BLIP (scene or object-focused)\n",
        "- Stores embeddings in Pinecone for semantic search\n",
        "- Enables natural language queries to find exact timestamps\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        "## Step 1: Installation & Setup\n",
        "\n",
        "Clone repository and install all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/pranavacchu/capstone-BLIP.git\n",
        "%cd capstone-BLIP\n",
        "\n",
        "# Install dependencies\n",
        "print(\"üì¶ Installing dependencies... This will take 3-5 minutes\")\n",
        "!pip install -q opencv-python-headless pillow numpy pandas tqdm python-dotenv\n",
        "!pip install -q torch torchvision transformers sentence-transformers\n",
        "!pip install -q pinecone FlagEmbedding timm supervision\n",
        "\n",
        "print(\"\\n‚úÖ Installation complete!\")\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\nüöÄ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No GPU detected. Using CPU (slower but functional)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## Step 2: Apply Hotfixes (If Needed)\n",
        "\n",
        "Fixes known issues in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hotfixes"
      },
      "outputs": [],
      "source": [
        "print(\"üîß Applying hotfixes...\")\n",
        "\n",
        "# Hotfix 1: Add deduplicate_embeddings method to TextEmbeddingGenerator\n",
        "with open('embedding_generator.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "if 'def deduplicate_embeddings' not in content:\n",
        "    print(\"   - Adding deduplicate_embeddings method...\")\n",
        "    marker = '    def get_embedding_statistics'\n",
        "    if marker in content:\n",
        "        dedupe_method = '''    def deduplicate_embeddings(self,\n",
        "                              embedded_frames: List[EmbeddedFrame],\n",
        "                              similarity_threshold: float = 0.95) -> List[EmbeddedFrame]:\n",
        "        \"\"\"\n",
        "        Remove duplicate embeddings based on similarity threshold\n",
        "        \"\"\"\n",
        "        if not embedded_frames or len(embedded_frames) <= 1:\n",
        "            return embedded_frames\n",
        "        \n",
        "        logger.info(f\"Deduplicating {len(embedded_frames)} embeddings with threshold {similarity_threshold}\")\n",
        "        \n",
        "        embeddings = np.array([ef.embedding for ef in embedded_frames])\n",
        "        keep_mask = np.ones(len(embedded_frames), dtype=bool)\n",
        "        \n",
        "        for i in range(len(embeddings)):\n",
        "            if not keep_mask[i]:\n",
        "                continue\n",
        "            for j in range(i + 1, len(embeddings)):\n",
        "                if not keep_mask[j]:\n",
        "                    continue\n",
        "                similarity = np.dot(embeddings[i], embeddings[j]) if self.normalize else \\\n",
        "                    np.dot(embeddings[i], embeddings[j]) / (np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j]))\n",
        "                if similarity >= similarity_threshold:\n",
        "                    keep_mask[j] = False\n",
        "        \n",
        "        unique_frames = [ef for ef, keep in zip(embedded_frames, keep_mask) if keep]\n",
        "        logger.info(f\"Removed {len(embedded_frames) - len(unique_frames)} duplicates, kept {len(unique_frames)} unique\")\n",
        "        return unique_frames\n",
        "\n",
        "'''\n",
        "        content = content.replace(marker, dedupe_method + marker)\n",
        "        with open('embedding_generator.py', 'w') as f:\n",
        "            f.write(content)\n",
        "        print(\"   ‚úì Added deduplicate_embeddings method\")\n",
        "else:\n",
        "    print(\"   ‚úì deduplicate_embeddings already exists\")\n",
        "\n",
        "# Hotfix 2: Fix Grounding DINO dtype mismatch\n",
        "print(\"   - Fixing Grounding DINO dtype mismatch...\")\n",
        "with open('object_detector.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "if 'torch_dtype=torch.float32' not in content:\n",
        "    # Ensure model is loaded with float32\n",
        "    print(\"   ‚ö† Grounding DINO should load with float32. Check object_detector.py line 79-82\")\n",
        "else:\n",
        "    print(\"   ‚úì Grounding DINO dtype fix already applied\")\n",
        "\n",
        "print(\"\\n‚úÖ Hotfixes complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reload_modules"
      },
      "outputs": [],
      "source": [
        "# Reload modules after hotfixes\n",
        "import sys\n",
        "for m in ['object_detector', 'object_caption_pipeline', 'video_search_engine', 'embedding_generator']:\n",
        "    if m in sys.modules:\n",
        "        del sys.modules[m]\n",
        "print(\"‚úÖ Modules reloaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "## Step 3: Configure Pinecone Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set your Pinecone credentials\n",
        "PINECONE_API_KEY = \"your_api_key_here\"  # Replace with your actual key\n",
        "PINECONE_HOST = \"https://your-index-host.pinecone.io\"  # Replace with your host\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "\n",
        "# Write to .env file\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(f\"PINECONE_API_KEY={PINECONE_API_KEY}\\n\")\n",
        "    f.write(f\"PINECONE_HOST={PINECONE_HOST}\\n\")\n",
        "    f.write(f\"PINECONE_ENVIRONMENT={PINECONE_ENVIRONMENT}\\n\")\n",
        "\n",
        "print(\"‚úÖ Configuration saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "## Step 4: Test Pinecone Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_connection"
      },
      "outputs": [],
      "source": [
        "from video_search_engine import VideoSearchEngine\n",
        "\n",
        "print(\"üîå Connecting to Pinecone...\")\n",
        "engine = VideoSearchEngine()\n",
        "\n",
        "# Get database stats\n",
        "stats = engine.get_index_stats()\n",
        "\n",
        "print(\"\\n‚úÖ Successfully connected to Pinecone!\")\n",
        "print(f\"\\nüìä Database Statistics:\")\n",
        "print(f\"   Index: capstone\")\n",
        "print(f\"   Total vectors: {stats.get('total_vectors', 0):,}\")\n",
        "print(f\"   Dimension: {stats.get('dimension', 1024)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5"
      },
      "source": [
        "## Step 5: Upload Video\n",
        "\n",
        "Choose how to get your video:\n",
        "1. Upload from computer\n",
        "2. Download from URL\n",
        "3. Download from YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_video"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import subprocess\n",
        "from urllib.parse import urlparse\n",
        "import cv2\n",
        "\n",
        "def upload_from_computer():\n",
        "    print(\"üìÅ Please select your video file...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        video_path = list(uploaded.keys())[0]\n",
        "        print(f\"‚úÖ Uploaded: {video_path}\")\n",
        "        return video_path\n",
        "    print(\"‚ùå No file uploaded\")\n",
        "    return None\n",
        "\n",
        "def download_from_url(url):\n",
        "    filename = os.path.basename(urlparse(url).path) or \"downloaded_video.mp4\"\n",
        "    print(f\"‚¨áÔ∏è Downloading from URL to {filename}...\")\n",
        "    \n",
        "    result = subprocess.run(\n",
        "        ['wget', '-O', filename, url, '--no-check-certificate', '-q', '--show-progress'],\n",
        "        capture_output=True, timeout=300\n",
        "    )\n",
        "    \n",
        "    if result.returncode == 0 and os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
        "        print(f\"‚úÖ Downloaded: {filename}\")\n",
        "        return filename\n",
        "    \n",
        "    # Fallback to curl\n",
        "    print(\"üîÑ Trying alternative method (curl)...\")\n",
        "    result = subprocess.run(\n",
        "        ['curl', '-L', '-o', filename, url, '--silent', '--show-error'],\n",
        "        capture_output=True, timeout=300\n",
        "    )\n",
        "    \n",
        "    if result.returncode == 0 and os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
        "        print(f\"‚úÖ Downloaded: {filename}\")\n",
        "        return filename\n",
        "    \n",
        "    print(\"‚ùå Download failed\")\n",
        "    return None\n",
        "\n",
        "def download_from_youtube(url):\n",
        "    print(\"‚¨áÔ∏è Downloading from YouTube...\")\n",
        "    subprocess.run(['pip', 'install', '-q', 'yt-dlp'], check=False)\n",
        "    \n",
        "    filename = \"youtube_video.mp4\"\n",
        "    result = subprocess.run(\n",
        "        ['yt-dlp', '-f', 'best[ext=mp4]/best', '-o', filename, '--no-playlist', '--quiet', '--progress', url],\n",
        "        capture_output=True, timeout=600\n",
        "    )\n",
        "    \n",
        "    if result.returncode == 0 and os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
        "        print(f\"‚úÖ Downloaded: {filename}\")\n",
        "        return filename\n",
        "    \n",
        "    print(\"‚ùå YouTube download failed\")\n",
        "    print(\"üí° Tips: Ensure video is public and not age-restricted\")\n",
        "    return None\n",
        "\n",
        "def validate_video(video_path):\n",
        "    if not os.path.exists(video_path):\n",
        "        return False\n",
        "    \n",
        "    file_size = os.path.getsize(video_path) / (1024*1024)\n",
        "    print(f\"\\nüìπ Video ready: {video_path} ({file_size:.1f} MB)\")\n",
        "    \n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if cap.isOpened():\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        duration = frame_count / fps if fps > 0 else 0\n",
        "        print(f\"   Duration: {duration:.1f}s | FPS: {fps:.1f} | Frames: {frame_count:,}\")\n",
        "        cap.release()\n",
        "        return True\n",
        "    \n",
        "    print(\"‚ö†Ô∏è Unable to read video file. It may be corrupted.\")\n",
        "    return False\n",
        "\n",
        "# Main upload logic\n",
        "print(\"üì§ Choose video source:\\n\")\n",
        "print(\"1. Upload from computer (recommended for small files < 100MB)\")\n",
        "print(\"2. Download from URL (direct video file)\")\n",
        "print(\"3. Download from YouTube URL\\n\")\n",
        "\n",
        "choice = input(\"Enter choice (1/2/3): \").strip()\n",
        "video_path = None\n",
        "\n",
        "if choice == \"1\":\n",
        "    video_path = upload_from_computer()\n",
        "elif choice == \"2\":\n",
        "    url = input(\"\\nEnter video URL: \").strip()\n",
        "    if url:\n",
        "        video_path = download_from_url(url)\n",
        "elif choice == \"3\":\n",
        "    url = input(\"\\nEnter YouTube URL: \").strip()\n",
        "    if url:\n",
        "        video_path = download_from_youtube(url)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Invalid choice\")\n",
        "\n",
        "# Validate\n",
        "if video_path and validate_video(video_path):\n",
        "    print(\"\\n‚úÖ Video is ready for processing\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No valid video available. Please run this cell again.\")\n",
        "    video_path = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6"
      },
      "source": [
        "## Step 6: Choose Captioning Method\n",
        "\n",
        "**Option 1: Standard BLIP** - Faster, generates general scene descriptions  \n",
        "**Option 2: Object Detection + BLIP** - Slower, focuses on detected objects with attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "choose_method"
      },
      "outputs": [],
      "source": [
        "print(\"Choose captioning method:\\n\")\n",
        "print(\"1. Standard BLIP (faster, general scene captions)\")\n",
        "print(\"2. Object Detection + BLIP (slower, object-focused)\\n\")\n",
        "\n",
        "method_choice = input(\"Enter choice (1/2, default=1): \").strip() or \"1\"\n",
        "use_object_detection = (method_choice == \"2\")\n",
        "\n",
        "if use_object_detection:\n",
        "    print(\"\\n‚ÑπÔ∏è Using Object Detection + BLIP pipeline\")\n",
        "    print(\"   Detects: bags, laptops, helmets, phones, people, vehicles, etc.\")\n",
        "else:\n",
        "    print(\"\\n‚ÑπÔ∏è Using Standard BLIP captioning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step7"
      },
      "source": [
        "## Step 7: Process Video\n",
        "\n",
        "This will:\n",
        "1. Extract frames (with similarity filtering)\n",
        "2. Generate captions (object-focused or scene-based)\n",
        "3. Create embeddings for semantic search\n",
        "4. Upload to Pinecone database\n",
        "\n",
        "**Expected time:**  \n",
        "- 1 min video: ~2-3 min with GPU  \n",
        "- 5 min video: ~8-10 min with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process_video"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "if 'video_path' not in locals() or not video_path:\n",
        "    print(\"‚ùå No video available. Please run the upload cell first.\")\n",
        "else:\n",
        "    # Set video name\n",
        "    video_name = input(\"Enter a name for this video (or press Enter for auto-name): \").strip()\n",
        "    if not video_name:\n",
        "        video_name = f\"video_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    \n",
        "    print(f\"\\nüé¨ Processing video: {video_name}\")\n",
        "    print(\"‚è≥ This will take a few minutes... Please wait.\\n\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Process the video\n",
        "        stats = engine.process_video(\n",
        "            video_path=video_path,\n",
        "            video_name=video_name,\n",
        "            save_frames=False,\n",
        "            upload_to_pinecone=True,\n",
        "            use_object_detection=use_object_detection\n",
        "        )\n",
        "        \n",
        "        processing_time = time.time() - start_time\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"\\n‚úÖ VIDEO PROCESSING COMPLETE!\\n\")\n",
        "        print(f\"üìä Processing Statistics:\")\n",
        "        print(f\"   Video name: {video_name}\")\n",
        "        print(f\"   Frames extracted: {stats['total_frames_extracted']:,}\")\n",
        "        print(f\"   Frames with captions: {stats['frames_with_captions']:,}\")\n",
        "        print(f\"   Unique embeddings: {stats.get('embeddings_generated', 0):,}\")\n",
        "        print(f\"   Uploaded to Pinecone: {stats['embeddings_uploaded']:,}\")\n",
        "        print(f\"   Processing time: {processing_time/60:.1f} minutes\")\n",
        "        print(f\"   Frame reduction: {stats.get('frame_reduction_percent', 0):.1f}%\")\n",
        "        \n",
        "        # Save video name for search\n",
        "        processed_video_name = video_name\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Error processing video: {e}\")\n",
        "        print(\"\\nüí° Troubleshooting tips:\")\n",
        "        print(\"   - GPU memory error: Restart runtime and try again\")\n",
        "        print(\"   - Video format error: Convert to MP4 format\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step8"
      },
      "source": [
        "## Step 8: Search Your Video\n",
        "\n",
        "Use natural language to find specific content in your video.\n",
        "\n",
        "**Example queries:**\n",
        "- \"person walking\"\n",
        "- \"black bag\"\n",
        "- \"someone with a laptop\"\n",
        "- \"red backpack\"\n",
        "- \"student on phone\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "search_single"
      },
      "outputs": [],
      "source": [
        "# Single search query\n",
        "query = input(\"üîç Enter your search query: \")\n",
        "\n",
        "print(f\"\\nSearching for: '{query}'...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "results = engine.search(\n",
        "    query=query,\n",
        "    top_k=5,\n",
        "    similarity_threshold=0.5\n",
        ")\n",
        "\n",
        "if results:\n",
        "    print(f\"\\n‚úÖ Found {len(results)} results:\\n\")\n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"{i}. ‚è±Ô∏è Timestamp: {result['time_formatted']}\")\n",
        "        print(f\"   üìù Caption: {result['caption']}\")\n",
        "        print(f\"   üìä Confidence: {result['similarity_score']:.1%}\")\n",
        "        print(f\"   üé• Video: {result['video_name']}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"\\n‚ùå No results found. Try:\")\n",
        "    print(\"   - Different search terms\")\n",
        "    print(\"   - More general queries\")\n",
        "    print(\"   - Lowering the similarity threshold\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step9"
      },
      "source": [
        "## Step 9: Batch Search (Multiple Queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch_search"
      },
      "outputs": [],
      "source": [
        "# Define multiple queries\n",
        "queries = [\n",
        "    \"person walking\",\n",
        "    \"backpack\",\n",
        "    \"laptop\",\n",
        "    \"phone\",\n",
        "    \"outdoor scene\"\n",
        "]\n",
        "\n",
        "print(\"üîç Running batch search...\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "batch_results = engine.batch_search(queries, top_k=3)\n",
        "\n",
        "for query, results in batch_results.items():\n",
        "    print(f\"\\nüìå Query: '{query}'\")\n",
        "    print(f\"   Found {len(results)} results\")\n",
        "    \n",
        "    if results:\n",
        "        for result in results[:2]:  # Show top 2\n",
        "            print(f\"   ‚îî‚îÄ {result['time_formatted']} - {result['caption'][:50]}... ({result['similarity_score']:.0%})\")\n",
        "    else:\n",
        "        print(\"   ‚îî‚îÄ No results\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step10"
      },
      "source": [
        "## Step 10: Advanced Search with Filters\n",
        "\n",
        "Search with additional constraints:\n",
        "- Filter by specific video\n",
        "- Search within time range\n",
        "- Adjust confidence threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "advanced_search"
      },
      "outputs": [],
      "source": [
        "query = input(\"Enter search query: \")\n",
        "\n",
        "# Optional: Time range filter\n",
        "use_time_filter = input(\"Filter by time range? (y/n): \").lower() == 'y'\n",
        "time_window = None\n",
        "if use_time_filter:\n",
        "    start_time = float(input(\"Start time (seconds): \"))\n",
        "    end_time = float(input(\"End time (seconds): \"))\n",
        "    time_window = (start_time, end_time)\n",
        "\n",
        "# Optional: Video filter\n",
        "video_filter = None\n",
        "if 'processed_video_name' in locals():\n",
        "    filter_video = input(f\"Search only in '{processed_video_name}'? (y/n): \").lower() == 'y'\n",
        "    if filter_video:\n",
        "        video_filter = processed_video_name\n",
        "\n",
        "# Perform search\n",
        "print(f\"\\nüîç Searching with filters...\")\n",
        "results = engine.search(\n",
        "    query=query,\n",
        "    top_k=10,\n",
        "    similarity_threshold=0.4,\n",
        "    video_filter=video_filter,\n",
        "    time_window=time_window\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Found {len(results)} results:\\n\")\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"{i}. {result['time_formatted']} - {result['caption'][:60]}... ({result['similarity_score']:.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step11"
      },
      "source": [
        "## Step 11: Interactive Search Interface\n",
        "\n",
        "Enter queries continuously. Type 'quit' to exit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interactive"
      },
      "outputs": [],
      "source": [
        "print(\"üéØ INTERACTIVE VIDEO SEARCH\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Enter your search queries (type 'quit' to exit)\\n\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"\\nüîç Search: \").strip()\n",
        "    \n",
        "    if query.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"\\nüëã Goodbye!\")\n",
        "        break\n",
        "    \n",
        "    if not query:\n",
        "        continue\n",
        "    \n",
        "    results = engine.search(query, top_k=5)\n",
        "    \n",
        "    if results:\n",
        "        print(f\"\\n‚úÖ Found {len(results)} results:\")\n",
        "        for i, result in enumerate(results, 1):\n",
        "            score_emoji = \"üü¢\" if result['similarity_score'] > 0.7 else \"üü°\" if result['similarity_score'] > 0.5 else \"üü†\"\n",
        "            print(f\"\\n{i}. {score_emoji} {result['time_formatted']} ({result['similarity_score']:.0%})\")\n",
        "            print(f\"   {result['caption']}\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå No results found. Try a different query.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleanup"
      },
      "source": [
        "## Cleanup (Optional)\n",
        "\n",
        "Free up GPU memory after processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cleanup_cell"
      },
      "outputs": [],
      "source": [
        "# Clear GPU cache and unload models\n",
        "engine.cleanup()\n",
        "print(\"‚úÖ Resources cleaned up\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
