{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Video Frame Search System with BLIP & Pinecone\n",
        "\n",
        "This notebook sets up a complete video semantic search engine that:\n",
        "- Extracts frames from videos\n",
        "- Generates captions using BLIP\n",
        "- Stores embeddings in Pinecone\n",
        "- Enables natural language search\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        " ## Step 1: Setup - Clone Repository & Install Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b742920-a36c-4548-d8fc-bbb88b19ef36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'capstone-BLIP'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 55 (delta 21), reused 49 (delta 15), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (55/55), 90.19 KiB | 4.51 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "/content/capstone-BLIP/capstone-BLIP/capstone-BLIP\n",
            "📦 Installing dependencies... This will take 3-5 minutes\n",
            "\n",
            "✅ Installation complete!\n",
            "\n",
            "🚀 GPU detected: Tesla T4\n",
            "   Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/pranavacchu/capstone-BLIP.git\n",
        "%cd capstone-BLIP\n",
        "\n",
        "# Install dependencies\n",
        "print(\"📦 Installing dependencies... This will take 3-5 minutes\")\n",
        "!pip install -q opencv-python-headless pillow numpy pandas tqdm python-dotenv\n",
        "!pip install -q torch torchvision transformers sentence-transformers\n",
        "!pip install -q pinecone FlagEmbedding\n",
        "\n",
        "print(\"\\n✅ Installation complete!\")\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"\\n🚀 GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"\\n⚠️ No GPU detected. Using CPU (slower but works)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Hotfix script to fix known issues in the video search system\n",
        "Run this in Colab after cloning the repository\n",
        "\"\"\"\n",
        "\n",
        "print(\"🔧 Applying hotfixes...\")\n",
        "\n",
        "# Hotfix 1: Add deduplicate_embeddings method to TextEmbeddingGenerator\n",
        "print(\"   - Adding deduplicate_embeddings method...\")\n",
        "\n",
        "with open('embedding_generator.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "if 'def deduplicate_embeddings' not in content:\n",
        "    marker = '    def get_embedding_statistics'\n",
        "    if marker in content:\n",
        "        dedupe_method = '''    def deduplicate_embeddings(self,\n",
        "                              embedded_frames: List[EmbeddedFrame],\n",
        "                              similarity_threshold: float = 0.95) -> List[EmbeddedFrame]:\n",
        "        \"\"\"\n",
        "        Remove duplicate embeddings based on similarity threshold\n",
        "\n",
        "        Args:\n",
        "            embedded_frames: List of EmbeddedFrame objects\n",
        "            similarity_threshold: Minimum similarity to consider as duplicate (0.0 to 1.0)\n",
        "\n",
        "        Returns:\n",
        "            List of unique EmbeddedFrame objects\n",
        "        \"\"\"\n",
        "        if not embedded_frames:\n",
        "            return []\n",
        "\n",
        "        if len(embedded_frames) <= 1:\n",
        "            return embedded_frames\n",
        "\n",
        "        logger.info(f\"Deduplicating {len(embedded_frames)} embeddings with threshold {similarity_threshold}\")\n",
        "\n",
        "        # Convert to numpy array for efficient computation\n",
        "        embeddings = np.array([ef.embedding for ef in embedded_frames])\n",
        "\n",
        "        # Track which embeddings to keep\n",
        "        keep_mask = np.ones(len(embedded_frames), dtype=bool)\n",
        "\n",
        "        # Compare each embedding with subsequent ones\n",
        "        for i in range(len(embeddings)):\n",
        "            if not keep_mask[i]:\n",
        "                continue\n",
        "\n",
        "            # Compute similarity with all subsequent embeddings\n",
        "            for j in range(i + 1, len(embeddings)):\n",
        "                if not keep_mask[j]:\n",
        "                    continue\n",
        "\n",
        "                # Compute cosine similarity\n",
        "                if self.normalize:\n",
        "                    # If normalized, use dot product\n",
        "                    similarity = np.dot(embeddings[i], embeddings[j])\n",
        "                else:\n",
        "                    # Compute cosine similarity manually\n",
        "                    similarity = np.dot(embeddings[i], embeddings[j]) / (\n",
        "                        np.linalg.norm(embeddings[i]) * np.linalg.norm(embeddings[j])\n",
        "                    )\n",
        "\n",
        "                # Mark as duplicate if similarity exceeds threshold\n",
        "                if similarity >= similarity_threshold:\n",
        "                    keep_mask[j] = False\n",
        "\n",
        "        # Filter embeddings based on keep mask\n",
        "        unique_frames = [ef for ef, keep in zip(embedded_frames, keep_mask) if keep]\n",
        "\n",
        "        removed_count = len(embedded_frames) - len(unique_frames)\n",
        "        logger.info(f\"Removed {removed_count} duplicate embeddings, kept {len(unique_frames)} unique\")\n",
        "\n",
        "        return unique_frames\n",
        "\n",
        "'''\n",
        "        content = content.replace(marker, dedupe_method + marker)\n",
        "\n",
        "        with open('embedding_generator.py', 'w') as f:\n",
        "            f.write(content)\n",
        "        print(\"   ✓ Added deduplicate_embeddings method\")\n",
        "    else:\n",
        "        print(\"   ⚠ Could not find insertion point\")\n",
        "else:\n",
        "    print(\"   ✓ deduplicate_embeddings already exists\")\n",
        "\n",
        "# Hotfix 2: Fix Grounding DINO dtype mismatch\n",
        "print(\"   - Fixing Grounding DINO dtype mismatch...\")\n",
        "\n",
        "with open('object_detector.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "if 'model_dtype = next(self.model.parameters()).dtype' not in content:\n",
        "    old_code = '''            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
        "\n",
        "            # Run detection\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)'''\n",
        "\n",
        "    new_code = '''            # Ensure dtype matches model weights (fp16 on CUDA)\n",
        "            model_dtype = next(self.model.parameters()).dtype\n",
        "            casted_inputs = {}\n",
        "            for k, v in inputs.items():\n",
        "                v = v.to(self.device)\n",
        "                if hasattr(v, 'dtype') and v.dtype.is_floating_point:\n",
        "                    v = v.to(model_dtype)\n",
        "                casted_inputs[k] = v\n",
        "\n",
        "            # Run detection\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**casted_inputs)'''\n",
        "\n",
        "    if old_code in content:\n",
        "        content = content.replace(old_code, new_code)\n",
        "        with open('object_detector.py', 'w') as f:\n",
        "            f.write(content)\n",
        "        print(\"   ✓ Fixed Grounding DINO dtype mismatch\")\n",
        "    else:\n",
        "        print(\"   ⚠ Could not find code to replace in object_detector.py\")\n",
        "else:\n",
        "    print(\"   ✓ Grounding DINO dtype fix already applied\")\n",
        "\n",
        "print(\"\\n✅ Hotfixes applied successfully!\")\n",
        "print(\"   You can now proceed with video processing\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRq_cGCWMbER",
        "outputId": "fbf0a256-5557-446a-dfd9-17f46b8cb73f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Applying hotfixes...\n",
            "   - Adding deduplicate_embeddings method...\n",
            "   ✓ deduplicate_embeddings already exists\n",
            "   - Fixing Grounding DINO dtype mismatch...\n",
            "   ✓ Grounding DINO dtype fix already applied\n",
            "\n",
            "✅ Hotfixes applied successfully!\n",
            "   You can now proceed with video processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Grounding DINO dependencies\n",
        "print(\"Installing Grounding DINO and dependencies...\")\n",
        "print(\"This may take 2-3 minutes...\")\n",
        "\n",
        "import subprocess\n",
        "subprocess.run(['pip', 'install', '-q', 'timm'], check=False)\n",
        "subprocess.run(['pip', 'install', '-q', 'supervision'], check=False)\n",
        "\n",
        "print(\"\\nGrounding DINO dependencies installed!\")\n",
        "print(\"Models will be downloaded automatically from Hugging Face on first use\")"
      ],
      "metadata": {
        "id": "yeN8iRp-vG6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0471444-87f8-445d-84ba-cf6ec01f001b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Grounding DINO and dependencies...\n",
            "This may take 2-3 minutes...\n",
            "\n",
            "Grounding DINO dependencies installed!\n",
            "Models will be downloaded automatically from Hugging Face on first use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## Step 2: Configure Pinecone API Key\n",
        "\n",
        "Enter your Pinecone credentials below:\n",
        "- **API Key**: Your Pinecone API key\n",
        "- **Index Host**: Your index URL (from Pinecone dashboard)\n",
        "\n",
        "Your current settings:\n",
        "```\n",
        "API Key: pcsk_51Fgoo_2S9NQf4CHi8LMpX7AXKv4TEHgRdXR3huZcCwBdJkr7BMvmdGHeRASrk5hkz4AH1\n",
        "Host: https://capstone-b5a0x4x.svc.aped-4627-b74a.pinecone.io\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c04dd06-21ff-4644-a900-f72c2fe2866c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Configuration saved!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set your Pinecone credentials\n",
        "PINECONE_API_KEY = \"pcsk_51Fgoo_2S9NQf4CHi8LMpX7AXKv4TEHgRdXR3huZcCwBdJkr7BMvmdGHeRASrk5hkz4AH1\"\n",
        "PINECONE_HOST = \"https://capstone-b5a0x4x.svc.aped-4627-b74a.pinecone.io\"\n",
        "PINECONE_ENVIRONMENT = \"us-east-1\"\n",
        "\n",
        "# Write to .env file\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(f\"PINECONE_API_KEY={PINECONE_API_KEY}\\n\")\n",
        "    f.write(f\"PINECONE_HOST={PINECONE_HOST}\\n\")\n",
        "    f.write(f\"PINECONE_ENVIRONMENT={PINECONE_ENVIRONMENT}\\n\")\n",
        "\n",
        "print(\"✅ Configuration saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "##  Step 3: Test Connection to Pinecone\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "test_connection",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee88a2fd-483d-4002-dbf6-af7fa1b50318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔌 Connecting to Pinecone...\n",
            "\n",
            "✅ Successfully connected to Pinecone!\n",
            "\n",
            "📊 Database Statistics:\n",
            "   Index: capstone\n",
            "   Total vectors: 35\n",
            "   Dimension: 1024\n",
            "   Capacity: Serverless\n"
          ]
        }
      ],
      "source": [
        "from video_search_engine import VideoSearchEngine\n",
        "\n",
        "print(\"🔌 Connecting to Pinecone...\")\n",
        "engine = VideoSearchEngine()\n",
        "\n",
        "# Get database stats\n",
        "stats = engine.get_index_stats()\n",
        "\n",
        "print(\"\\n✅ Successfully connected to Pinecone!\")\n",
        "print(f\"\\n📊 Database Statistics:\")\n",
        "print(f\"   Index: capstone\")\n",
        "print(f\"   Total vectors: {stats.get('total_vectors', 0):,}\")\n",
        "print(f\"   Dimension: {stats.get('dimension', 1024)}\")\n",
        "print(f\"   Capacity: Serverless\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "## Step 4: Upload a Video File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "upload_video",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "e4e878bb-6de1-4ed9-a174-423f1367d072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📤 Choose how to get your video:\n",
            "\n",
            "1. Upload from computer (recommended for small files < 100MB)\n",
            "2. Download from URL (direct video file)\n",
            "3. Download from YouTube URL\n",
            "\n",
            "Enter choice (1/2/3): 1\n",
            "\n",
            "📁 Please select your video file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-049b492e-464a-4d47-abd5-6055dfed6d7b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-049b492e-464a-4d47-abd5-6055dfed6d7b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving video_output 2_object.mp4 to video_output 2_object (1).mp4\n",
            "✅ Uploaded: video_output 2_object (1).mp4\n",
            "\n",
            "📹 Video ready: video_output 2_object (1).mp4 (7.4 MB)\n",
            "   Duration: 75.5 seconds\n",
            "   FPS: 29.0\n",
            "   Total frames: 2,190\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import subprocess\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "print(\"📤 Choose how to get your video:\\n\")\n",
        "print(\"1. Upload from computer (recommended for small files < 100MB)\")\n",
        "print(\"2. Download from URL (direct video file)\")\n",
        "print(\"3. Download from YouTube URL\\n\")\n",
        "\n",
        "choice = input(\"Enter choice (1/2/3): \").strip()\n",
        "video_path = None\n",
        "\n",
        "if choice == \"1\":\n",
        "    print(\"\\n📁 Please select your video file...\")\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        video_path = list(uploaded.keys())[0]\n",
        "        print(f\"✅ Uploaded: {video_path}\")\n",
        "    else:\n",
        "        print(\"❌ No file uploaded\")\n",
        "\n",
        "elif choice == \"2\":\n",
        "    video_url = input(\"\\nEnter video URL (direct link to .mp4, .avi, etc.): \").strip()\n",
        "\n",
        "    if not video_url:\n",
        "        print(\"❌ No URL provided\")\n",
        "    else:\n",
        "        # Extract filename from URL or use default\n",
        "        parsed_url = urlparse(video_url)\n",
        "        url_filename = os.path.basename(parsed_url.path)\n",
        "\n",
        "        # Use URL filename if it has an extension, otherwise use default\n",
        "        if url_filename and '.' in url_filename:\n",
        "            video_filename = url_filename\n",
        "        else:\n",
        "            video_filename = \"downloaded_video.mp4\"\n",
        "\n",
        "        print(f\"⬇️ Downloading from URL...\")\n",
        "        print(f\"   Target file: {video_filename}\")\n",
        "\n",
        "        try:\n",
        "            # Use subprocess for better control\n",
        "            result = subprocess.run(\n",
        "                ['wget', '-O', video_filename, video_url, '--no-check-certificate', '-q', '--show-progress'],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=300\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0 and os.path.exists(video_filename):\n",
        "                if os.path.getsize(video_filename) > 0:\n",
        "                    video_path = video_filename\n",
        "                    print(f\"✅ Downloaded successfully: {video_filename}\")\n",
        "                else:\n",
        "                    print(f\"❌ Download failed: File is empty\")\n",
        "                    if os.path.exists(video_filename):\n",
        "                        os.remove(video_filename)\n",
        "            else:\n",
        "                print(f\"❌ Download failed: wget returned code {result.returncode}\")\n",
        "                # Try alternative method with curl\n",
        "                print(\"\\n🔄 Trying alternative download method (curl)...\")\n",
        "                result2 = subprocess.run(\n",
        "                    ['curl', '-L', '-o', video_filename, video_url, '--silent', '--show-error'],\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    timeout=300\n",
        "                )\n",
        "\n",
        "                if result2.returncode == 0 and os.path.exists(video_filename) and os.path.getsize(video_filename) > 0:\n",
        "                    video_path = video_filename\n",
        "                    print(f\"✅ Downloaded successfully with curl: {video_filename}\")\n",
        "                else:\n",
        "                    print(f\"❌ Alternative download also failed\")\n",
        "                    print(\"   Please check if the URL is accessible and try again\")\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"❌ Download timed out (>5 minutes). File may be too large.\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Download error: {e}\")\n",
        "\n",
        "elif choice == \"3\":\n",
        "    youtube_url = input(\"\\nEnter YouTube URL (video or shorts): \").strip()\n",
        "\n",
        "    if not youtube_url:\n",
        "        print(\"❌ No URL provided\")\n",
        "    else:\n",
        "        print(\"⬇️ Downloading from YouTube...\")\n",
        "        print(\"   Installing yt-dlp (if needed)...\")\n",
        "\n",
        "        # Install yt-dlp if not present\n",
        "        subprocess.run(['pip', 'install', '-q', 'yt-dlp'], check=False)\n",
        "\n",
        "        video_filename = \"youtube_video.mp4\"\n",
        "\n",
        "        try:\n",
        "            print(f\"   Fetching video info...\")\n",
        "\n",
        "            # Download with yt-dlp\n",
        "            result = subprocess.run(\n",
        "                [\n",
        "                    'yt-dlp',\n",
        "                    '-f', 'best[ext=mp4]/best',  # Best quality MP4\n",
        "                    '-o', video_filename,\n",
        "                    '--no-playlist',\n",
        "                    '--quiet',\n",
        "                    '--progress',\n",
        "                    youtube_url\n",
        "                ],\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=600  # 10 minute timeout for YouTube\n",
        "            )\n",
        "\n",
        "            if result.returncode == 0 and os.path.exists(video_filename):\n",
        "                if os.path.getsize(video_filename) > 0:\n",
        "                    video_path = video_filename\n",
        "                    print(f\"✅ Downloaded successfully: {video_filename}\")\n",
        "                else:\n",
        "                    print(f\"❌ Download failed: File is empty\")\n",
        "                    if os.path.exists(video_filename):\n",
        "                        os.remove(video_filename)\n",
        "            else:\n",
        "                print(f\"❌ YouTube download failed\")\n",
        "                if result.stderr:\n",
        "                    print(f\"   Error: {result.stderr[:300]}\")\n",
        "                print(\"\\n💡 Troubleshooting tips:\")\n",
        "                print(\"   - Make sure the video is public and not age-restricted\")\n",
        "                print(\"   - Try using Option 1 to upload the video manually\")\n",
        "                print(\"   - Check if the URL is correct\")\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"❌ Download timed out (>10 minutes).\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Download error: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"⚠️ Invalid choice. Please choose option 1, 2, or 3.\")\n",
        "\n",
        "# Validate the video file\n",
        "if video_path:\n",
        "    if os.path.exists(video_path):\n",
        "        file_size = os.path.getsize(video_path) / (1024*1024)  # MB\n",
        "        print(f\"\\n📹 Video ready: {video_path} ({file_size:.1f} MB)\")\n",
        "\n",
        "        # Verify it's a valid video file\n",
        "        import cv2\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if cap.isOpened():\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            duration = frame_count / fps if fps > 0 else 0\n",
        "            print(f\"   Duration: {duration:.1f} seconds\")\n",
        "            print(f\"   FPS: {fps:.1f}\")\n",
        "            print(f\"   Total frames: {frame_count:,}\")\n",
        "            cap.release()\n",
        "        else:\n",
        "            print(\"\\n⚠️ Warning: Unable to read video file. It may be corrupted.\")\n",
        "            print(\"   Please try a different video or URL.\")\n",
        "            video_path = None\n",
        "    else:\n",
        "        print(f\"\\n❌ Error: File not found at {video_path}\")\n",
        "        video_path = None\n",
        "\n",
        "if not video_path:\n",
        "    print(\"\\n❌ No valid video file available. Please run this cell again.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Choose your captioning method:\\n\")\n",
        "print(\"1. Standard BLIP (faster, general scene captions)\")\n",
        "print(\"2. Object Detection + BLIP (slower, object-focused)\")\n",
        "print()\n",
        "\n",
        "method_choice = input(\"Enter choice (1/2, default=1): \").strip() or \"1\"\n",
        "use_object_detection = (method_choice == \"2\")\n",
        "\n",
        "if use_object_detection:\n",
        "    print(\"\\nUsing Object Detection + BLIP pipeline\")\n",
        "    print(\"   Detects objects: bags, laptops, helmets, phones, etc.\")\n",
        "else:\n",
        "    print(\"\\nUsing Standard BLIP captioning\")"
      ],
      "metadata": {
        "id": "MwRP7HFQvYl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b015c715-2fdb-4c84-ff55-19c07b1cfa3f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose your captioning method:\n",
            "\n",
            "1. Standard BLIP (faster, general scene captions)\n",
            "2. Object Detection + BLIP (slower, object-focused)\n",
            "\n",
            "Enter choice (1/2, default=1): 2\n",
            "\n",
            "Using Object Detection + BLIP pipeline\n",
            "   Detects objects: bags, laptops, helmets, phones, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step5"
      },
      "source": [
        "## Step 5: Process the Video\n",
        "\n",
        "This will:\n",
        "1. Extract frames from the video (removing redundant frames)\n",
        "2. Generate captions using BLIP AI model\n",
        "3. Create embeddings for semantic search\n",
        "4. Upload to Pinecone database\n",
        "\n",
        "**Expected time:**\n",
        "- 1 minute video: ~2-3 minutes with GPU\n",
        "- 5 minute video: ~8-10 minutes with GPU\n",
        "- CPU mode: 3-5x slower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "process_video",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357,
          "referenced_widgets": [
            "ef59798f0229466899147322f2b31a45",
            "505d9da37f51409b8e28a3f82d816ff2",
            "9c22256ab7ef49b2a7743b14b4a495b5",
            "fca859522d4c45a2adde69454ce50756",
            "9624171a7333425ba2b9e9530e838418",
            "53ca407b2198478c8efacf873d822f04",
            "e2543f42a34c4ac9a15c79e1508a0ff4",
            "8384812b30da4a839d4431dd9303366d",
            "362a6cb805b041958576f08784aff45e",
            "b70f018fd4034f2f970004cbb93461ce",
            "e58d999113b84116833e099b176bd0f8"
          ]
        },
        "outputId": "9cc75779-aac8-4b24-892e-e88c467f80e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a name for this video (or press Enter for auto-name): test\n",
            "\n",
            "🎬 Processing video: test\n",
            "⏳ This will take a few minutes... Please wait.\n",
            "\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting frames: 100%|██████████| 2190/2190 [00:03<00:00, 582.39it/s]\n",
            "Processing frames:   0%|          | 0/1 [00:00<?, ?it/s]ERROR:object_detector:Error during object detection: Input type (float) and bias type (c10::Half) should be the same\n",
            "Processing frames: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef59798f0229466899147322f2b31a45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:video_search_engine:Error processing video: 'TextEmbeddingGenerator' object has no attribute 'deduplicate_embeddings'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "❌ Error processing video: 'TextEmbeddingGenerator' object has no attribute 'deduplicate_embeddings'\n",
            "\n",
            "Troubleshooting tips:\n",
            "- If GPU memory error: Restart runtime and try again\n",
            "- If video format error: Convert video to MP4 format\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "if 'video_path' not in locals() or not video_path:\n",
        "    print(\"❌ Please upload a video first (run the previous cell)\")\n",
        "else:\n",
        "    # Set video name\n",
        "    video_name = input(\"Enter a name for this video (or press Enter for auto-name): \").strip()\n",
        "    if not video_name:\n",
        "        video_name = f\"video_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "    print(f\"\\n🎬 Processing video: {video_name}\")\n",
        "    print(\"⏳ This will take a few minutes... Please wait.\\n\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Process the video\n",
        "        stats = engine.process_video(\n",
        "            video_path=video_path,\n",
        "            video_name=video_name,\n",
        "            save_frames=False,  # Set to True to save frames\n",
        "            upload_to_pinecone=True,\n",
        "            use_object_detection=use_object_detection  # ADD THIS LINE\n",
        "        )\n",
        "\n",
        "        processing_time = time.time() - start_time\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"\\n✅ VIDEO PROCESSING COMPLETE!\\n\")\n",
        "        print(f\"📊 Processing Statistics:\")\n",
        "        print(f\"   Video name: {video_name}\")\n",
        "        print(f\"   Frames extracted: {stats['total_frames_extracted']:,}\")\n",
        "        print(f\"   Frames with captions: {stats['frames_with_captions']:,}\")\n",
        "        print(f\"   Captions before dedupe: {stats.get('captions_before_dedupe', stats['frames_with_captions']):,}\")\n",
        "        print(f\"   Unique embeddings: {stats.get('embeddings_generated', 0):,}\")\n",
        "        print(f\"   ✅ Actually uploaded: {stats['embeddings_uploaded']:,}\")\n",
        "        print(f\"   Processing time: {processing_time/60:.1f} minutes\")\n",
        "        print(f\"\\n   Frame reduction: {stats.get('frame_reduction_percent', 0):.1f}%\")\n",
        "\n",
        "        # Save video_name for next steps\n",
        "        processed_video_name = video_name\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Error processing video: {e}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"- If GPU memory error: Restart runtime and try again\")\n",
        "        print(\"- If video format error: Convert video to MP4 format\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step6"
      },
      "source": [
        "## Step 6: Search Your Video!\n",
        "\n",
        "Now you can search for content using natural language queries.\n",
        "\n",
        "**Example queries:**\n",
        "- \"person walking\"\n",
        "- \"black bag\"\n",
        "- \"someone talking on phone\"\n",
        "- \"car driving\"\n",
        "- \"red shirt\"\n",
        "\n",
        "The system will return timestamps where that content appears!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "search_single",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "1e412975-a4c3-4bc2-83d6-163afb485961"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4062749137.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Single search query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔍 Enter your search query: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nSearching for: '{query}'...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Single search query\n",
        "query = input(\"🔍 Enter your search query: \")\n",
        "\n",
        "print(f\"\\nSearching for: '{query}'...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "results = engine.search(\n",
        "    query=query,\n",
        "    top_k=5,\n",
        "    similarity_threshold=0.5\n",
        ")\n",
        "\n",
        "if results:\n",
        "    print(f\"\\n✅ Found {len(results)} results:\\n\")\n",
        "\n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"{i}. ⏱️ Timestamp: {result['time_formatted']}\")\n",
        "        print(f\"   📝 Caption: {result['caption']}\")\n",
        "        print(f\"   📊 Confidence: {result['similarity_score']:.1%}\")\n",
        "        print(f\"   🎥 Video: {result['video_name']}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"\\n❌ No results found. Try:\")\n",
        "    print(\"   - Different search terms\")\n",
        "    print(\"   - More general queries\")\n",
        "    print(\"   - Lowering the similarity threshold\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step7"
      },
      "source": [
        "## Step 7: Batch Search (Multiple Queries)\n",
        "\n",
        "Search for multiple things at once!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "batch_search"
      },
      "outputs": [],
      "source": [
        "# Define multiple queries\n",
        "queries = [\n",
        "    \"person walking\",\n",
        "    \"someone sitting\",\n",
        "    \"black bag\",\n",
        "    \"outdoor scene\",\n",
        "    \"person talking\"\n",
        "]\n",
        "\n",
        "print(\"🔍 Running batch search...\\n\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "batch_results = engine.batch_search(queries, top_k=3)\n",
        "\n",
        "for query, results in batch_results.items():\n",
        "    print(f\"\\n📌 Query: '{query}'\")\n",
        "    print(f\"   Found {len(results)} results\")\n",
        "\n",
        "    if results:\n",
        "        for result in results[:2]:  # Show top 2\n",
        "            print(f\"   └─ {result['time_formatted']} - {result['caption'][:50]}... ({result['similarity_score']:.0%})\")\n",
        "    else:\n",
        "        print(\"   └─ No results\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step8"
      },
      "source": [
        "## Step 8: Advanced Search with Filters\n",
        "\n",
        "Search with additional filters:\n",
        "- Filter by specific video\n",
        "- Search within time range\n",
        "- Adjust confidence threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "advanced_search"
      },
      "outputs": [],
      "source": [
        "# Advanced search example\n",
        "query = input(\"Enter search query: \")\n",
        "\n",
        "# Optional: Filter by time window (in seconds)\n",
        "use_time_filter = input(\"Filter by time range? (y/n): \").lower() == 'y'\n",
        "\n",
        "time_window = None\n",
        "if use_time_filter:\n",
        "    start_time = float(input(\"Start time (seconds): \"))\n",
        "    end_time = float(input(\"End time (seconds): \"))\n",
        "    time_window = (start_time, end_time)\n",
        "\n",
        "# Optional: Filter by video name\n",
        "video_filter = None\n",
        "if 'processed_video_name' in locals():\n",
        "    filter_video = input(f\"Search only in '{processed_video_name}'? (y/n): \").lower() == 'y'\n",
        "    if filter_video:\n",
        "        video_filter = processed_video_name\n",
        "\n",
        "# Perform search\n",
        "print(f\"\\n🔍 Searching with filters...\")\n",
        "results = engine.search(\n",
        "    query=query,\n",
        "    top_k=10,\n",
        "    similarity_threshold=0.4,  # Lower threshold for more results\n",
        "    video_filter=video_filter,\n",
        "    time_window=time_window\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Found {len(results)} results:\\n\")\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"{i}. {result['time_formatted']} - {result['caption'][:60]}... ({result['similarity_score']:.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step11"
      },
      "source": [
        "## Step 9: Interactive Search Interface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interactive"
      },
      "outputs": [],
      "source": [
        "print(\"🎯 INTERACTIVE VIDEO SEARCH\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Enter your search queries (type 'quit' to exit)\\n\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"\\n🔍 Search: \").strip()\n",
        "\n",
        "    if query.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"\\n👋 Goodbye!\")\n",
        "        break\n",
        "\n",
        "    if not query:\n",
        "        continue\n",
        "\n",
        "    results = engine.search(query, top_k=5)\n",
        "\n",
        "    if results:\n",
        "        print(f\"\\n✅ Found {len(results)} results:\")\n",
        "        for i, result in enumerate(results, 1):\n",
        "            score_emoji = \"🟢\" if result['similarity_score'] > 0.7 else \"🟡\" if result['similarity_score'] > 0.5 else \"🟠\"\n",
        "            print(f\"\\n{i}. {score_emoji} {result['time_formatted']} ({result['similarity_score']:.0%})\")\n",
        "            print(f\"   {result['caption']}\")\n",
        "    else:\n",
        "        print(\"\\n❌ No results found. Try a different query.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef59798f0229466899147322f2b31a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_505d9da37f51409b8e28a3f82d816ff2",
              "IPY_MODEL_9c22256ab7ef49b2a7743b14b4a495b5",
              "IPY_MODEL_fca859522d4c45a2adde69454ce50756"
            ],
            "layout": "IPY_MODEL_9624171a7333425ba2b9e9530e838418"
          }
        },
        "505d9da37f51409b8e28a3f82d816ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53ca407b2198478c8efacf873d822f04",
            "placeholder": "​",
            "style": "IPY_MODEL_e2543f42a34c4ac9a15c79e1508a0ff4",
            "value": "Batches: 100%"
          }
        },
        "9c22256ab7ef49b2a7743b14b4a495b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8384812b30da4a839d4431dd9303366d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_362a6cb805b041958576f08784aff45e",
            "value": 1
          }
        },
        "fca859522d4c45a2adde69454ce50756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b70f018fd4034f2f970004cbb93461ce",
            "placeholder": "​",
            "style": "IPY_MODEL_e58d999113b84116833e099b176bd0f8",
            "value": " 1/1 [00:00&lt;00:00, 26.47it/s]"
          }
        },
        "9624171a7333425ba2b9e9530e838418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ca407b2198478c8efacf873d822f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2543f42a34c4ac9a15c79e1508a0ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8384812b30da4a839d4431dd9303366d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362a6cb805b041958576f08784aff45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b70f018fd4034f2f970004cbb93461ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58d999113b84116833e099b176bd0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}